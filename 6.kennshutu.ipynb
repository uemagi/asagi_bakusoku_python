{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip3 install --upgrade azure-cognitiveservices-vision-computervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /Users/uedaasagi/opt/anaconda3/lib/python3.8/site-packages (8.0.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "from array import array\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time\n",
    "\n",
    "subscription_key = \"451eddb3b4f349878ab3f0029e7b33bf\"\n",
    "endpoint = \"https://20210522-udemy-bakusoku.cognitiveservices.azure.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_image_url = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/landmark.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Describe an image - remote =====\n",
      "Description of remote image: \n",
      "'an ancient city with many ruins with Colosseum in the background' with confidence 33.80%\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Describe an image - remote =====\")\n",
    "\n",
    "description_results = computervision_client.describe_image(remote_image_url )\n",
    "\n",
    "print(\"Description of remote image: \")\n",
    "if (len(description_results.captions) == 0):\n",
    "    print(\"No description detected.\")\n",
    "else:\n",
    "    for caption in description_results.captions:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(caption.text, caption.confidence * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 画像カテゴリーの取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Categorize an image - remote =====\n",
      "Categories from remote image: \n",
      "'building_' with confidence 31.64%\n",
      "'others_' with confidence 0.39%\n",
      "'outdoor_' with confidence 3.91%\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Categorize an image - remote =====\")\n",
    "\n",
    "remote_image_features = [\"categories\"]\n",
    "\n",
    "categorize_results_remote = computervision_client.analyze_image(remote_image_url , remote_image_features)\n",
    "\n",
    "\n",
    "print(\"Categories from remote image: \")\n",
    "if (len(categorize_results_remote.categories) == 0):\n",
    "    print(\"No categories detected.\")\n",
    "else:\n",
    "    for category in categorize_results_remote.categories:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(category.name, category.score * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像タグの取得\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Tag an image - remote =====\n",
      "Tags in the remote image: \n",
      "'outdoor' with confidence 99.00%\n",
      "'building' with confidence 98.81%\n",
      "'sky' with confidence 98.21%\n",
      "'stadium' with confidence 98.17%\n",
      "'ancient rome' with confidence 96.16%\n",
      "'ruins' with confidence 95.04%\n",
      "'amphitheatre' with confidence 93.99%\n",
      "'ancient roman architecture' with confidence 92.65%\n",
      "'historic site' with confidence 89.55%\n",
      "'ancient history' with confidence 89.54%\n",
      "'history' with confidence 86.72%\n",
      "'archaeological site' with confidence 84.41%\n",
      "'travel' with confidence 65.85%\n",
      "'large' with confidence 61.02%\n",
      "'city' with confidence 56.57%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"===== Tag an image - remote =====\")\n",
    "\n",
    "tags_result_remote = computervision_client.tag_image(remote_image_url )\n",
    "\n",
    "\n",
    "print(\"Tags in the remote image: \")\n",
    "if (len(tags_result_remote.tags) == 0):\n",
    "    print(\"No tags detected.\")\n",
    "else:\n",
    "    for tag in tags_result_remote.tags:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(tag.name, tag.confidence * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  物体を検出する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Detect Objects - remote =====\n",
      "Detecting objects in remote image:\n",
      "object at location 213, 365, 85, 208\n",
      "object at location 218, 402, 179, 384\n",
      "object at location 238, 417, 298, 416\n",
      "object at location 116, 419, 60, 386\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"===== Detect Objects - remote =====\")\n",
    "\n",
    "remote_image_url_objects = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/objects.jpg\"\n",
    "\n",
    "detect_objects_results_remote = computervision_client.detect_objects(remote_image_url_objects)\n",
    "\n",
    "print(\"Detecting objects in remote image:\")\n",
    "if len(detect_objects_results_remote.objects) == 0:\n",
    "    print(\"No objects detected.\")\n",
    "else:\n",
    "    for object in detect_objects_results_remote.objects:\n",
    "        print(\"object at location {}, {}, {}, {}\".format( \\\n",
    "        object.rectangle.x, object.rectangle.x + object.rectangle.w, \\\n",
    "        object.rectangle.y, object.rectangle.y + object.rectangle.h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ローカルファイルに対応させる\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Detect Objects - local =====\n",
      "Detecting objects in local image:\n",
      "object at location 727, 804, 656, 749\n",
      "object at location 907, 971, 693, 790\n",
      "object at location 574, 656, 905, 971\n",
      "object at location 904, 1053, 815, 982\n",
      "object at location 440, 573, 974, 1052\n",
      "object at location 1068, 1121, 927, 1005\n",
      "object at location 1221, 1318, 948, 1030\n",
      "object at location 364, 442, 1014, 1103\n",
      "object at location 1298, 1380, 1009, 1097\n",
      "object at location 530, 765, 342, 927\n",
      "object at location 741, 972, 389, 773\n",
      "object at location 302, 570, 297, 1068\n",
      "object at location 1003, 1230, 327, 1021\n",
      "object at location 1195, 1478, 320, 1051\n",
      "object at location 678, 1023, 716, 1108\n"
     ]
    }
   ],
   "source": [
    "local_image_path ='inntai_photo.jpg'\n",
    "local_image = open(local_image_path, \"rb\")\n",
    "\n",
    "\n",
    "print(\"===== Detect Objects - local =====\")\n",
    "\n",
    "\n",
    "detect_objects_results = computervision_client.detect_objects_in_stream(local_image)\n",
    "\n",
    "print(\"Detecting objects in local image:\")\n",
    "if len(detect_objects_results.objects) == 0:\n",
    "    print(\"No objects detected.\")\n",
    "else:\n",
    "    for object in detect_objects_results.objects:\n",
    "        print(\"object at location {}, {}, {}, {}\".format( \\\n",
    "        object.rectangle.x, object.rectangle.x + object.rectangle.w, \\\n",
    "        object.rectangle.y, object.rectangle.y + object.rectangle.h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  get_tags(filepath):\n",
    "    local_image = open(filepath, \"rb\")\n",
    "\n",
    "    tags_result = computervision_client.tag_image_in_stream(local_image)\n",
    "    tags = tags_result.tags\n",
    "\n",
    "    tags_name =[]\n",
    "    for tag in tags:\n",
    "        tags_name.append(tag.name)\n",
    "\n",
    "    return tags_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sport',\n",
       " 'person',\n",
       " 'athletic game',\n",
       " 'footwear',\n",
       " 'man',\n",
       " 'clothing',\n",
       " 'sports equipment',\n",
       " 'ball',\n",
       " 'group',\n",
       " 'boy',\n",
       " 'basketball court',\n",
       " 'sportswear',\n",
       " 'field house',\n",
       " 'sports uniform',\n",
       " 'indoor',\n",
       " 'team sport',\n",
       " 'basketball',\n",
       " 'ball game',\n",
       " 'basketball player',\n",
       " 'playing',\n",
       " 'people',\n",
       " 'court',\n",
       " 'floor',\n",
       " 'player']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath ='inntai_photo.jpg'\n",
    "get_tags(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_objects(filepath):\n",
    "    local_image = open(filepath, \"rb\")\n",
    "\n",
    "\n",
    "    detect_objects_results = computervision_client.detect_objects_in_stream(local_image)\n",
    "    objects = detect_objects_results.objects\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<azure.cognitiveservices.vision.computervision.models._models_py3.DetectedObject at 0x7fb640502cd0>,\n",
       " <azure.cognitiveservices.vision.computervision.models._models_py3.DetectedObject at 0x7fb6402b8250>,\n",
       " <azure.cognitiveservices.vision.computervision.models._models_py3.DetectedObject at 0x7fb640502c70>,\n",
       " <azure.cognitiveservices.vision.computervision.models._models_py3.DetectedObject at 0x7fb64027ae20>,\n",
       " <azure.cognitiveservices.vision.computervision.models._models_py3.DetectedObject at 0x7fb640180940>,\n",
       " <azure.cognitiveservices.vision.computervision.models._models_py3.DetectedObject at 0x7fb640b89c70>,\n",
       " <azure.cognitiveservices.vision.computervision.models._models_py3.DetectedObject at 0x7fb63f66f100>,\n",
       " <azure.cognitiveservices.vision.computervision.models._models_py3.DetectedObject at 0x7fb63f659760>,\n",
       " <azure.cognitiveservices.vision.computervision.models._models_py3.DetectedObject at 0x7fb6404cb730>,\n",
       " <azure.cognitiveservices.vision.computervision.models._models_py3.DetectedObject at 0x7fb6402b8550>,\n",
       " <azure.cognitiveservices.vision.computervision.models._models_py3.DetectedObject at 0x7fb63f4e4e50>,\n",
       " <azure.cognitiveservices.vision.computervision.models._models_py3.DetectedObject at 0x7fb6404e2250>,\n",
       " <azure.cognitiveservices.vision.computervision.models._models_py3.DetectedObject at 0x7fb63f54b880>,\n",
       " <azure.cognitiveservices.vision.computervision.models._models_py3.DetectedObject at 0x7fb63f54b1f0>,\n",
       " <azure.cognitiveservices.vision.computervision.models._models_py3.DetectedObject at 0x7fb63f54b970>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath ='inntai_photo.jpg'\n",
    "detect_objects(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
